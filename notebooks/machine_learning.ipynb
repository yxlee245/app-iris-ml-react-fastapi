{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945f320c",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44e31e",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc917c2",
   "metadata": {},
   "source": [
    "Configuration for Jupyter to automatically apply changes in code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613c8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a71f92",
   "metadata": {},
   "source": [
    "Add parent directory (`server`) to system path, to be able to import modules from `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcbe15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597dee0",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedc131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, Any, Tuple, Union\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from src_backend.util import (\n",
    "    MODELS_DIR, MODEL_LOGREG_FN, MODEL_KNN_FN, MODEL_RF_FN, MODEL_GBM_FN\n",
    ")\n",
    "from src_backend.data import TrainingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b62c5",
   "metadata": {},
   "source": [
    "## Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a403b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrainingPipeline(test_size=0.2, random_state=0)\n",
    "pipeline.ingest()\n",
    "X_train, X_test, y_train, y_test = pipeline.output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034868c",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770143e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Types\n",
    "ModelTypes = Union[\n",
    "    LogisticRegression, KNeighborsClassifier,\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ea5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform hyperparameter tuning and return trained model\n",
    "def tune_hyperparam(\n",
    "    clf_class, hyperparam_grid: Dict[str, Iterable], X_train, y_train,\n",
    "    fixed_hyperparams: Dict[str, Any] = {}, num_folds: int = 5\n",
    ") -> Tuple[ModelTypes, Dict[str, Any]]:\n",
    "    # Perform grid search over defined hyperparameters\n",
    "    clf = clf_class(**fixed_hyperparams)\n",
    "    gs_estimator = GridSearchCV(clf, hyperparam_grid, scoring=\"accuracy\", cv=num_folds)\n",
    "    gs_estimator.fit(X_train, y_train)\n",
    "    print(f'Best hyperparameters found: {gs_estimator.best_params_}')\n",
    "    \n",
    "    # Retrain model on entire training set\n",
    "    clf_new = clf_class(**{**fixed_hyperparams, **gs_estimator.best_params_})\n",
    "    clf_new.fit(X_train, y_train)\n",
    "    return clf_new\n",
    "\n",
    "# Function to compute training and test scores\n",
    "def compute_scores(clf: ModelTypes, X_train, X_test, y_train, y_test) -> None:\n",
    "    # Compute training accuracy\n",
    "    predictions_train = clf.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, predictions_train)\n",
    "\n",
    "    # Compute test accuracy\n",
    "    predictions_test = clf.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "    print(f\"Training accuracy: {acc_train}\")\n",
    "    print(f\"Test accuarcy: {acc_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520df1ee",
   "metadata": {},
   "source": [
    "### Logistic Regression (One-vs-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16899474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'C': 1, 'l1_ratio': 0.0}\n",
      "Training accuracy: 0.9833333333333333\n",
      "Test accuarcy: 1.0\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define hyperparameters to be searched during tuning\n",
    "hyperparam_grid = {\n",
    "    \"C\": [10 ** i for i in range(-2, 3)],\n",
    "    \"l1_ratio\": [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "# Define hyperparameters to be fixed\n",
    "fixed_hyperparams = {\n",
    "    \"penalty\": \"elasticnet\",\n",
    "    \"solver\": \"saga\",\n",
    "    \"tol\": 1e-3,\n",
    "    \"max_iter\": 500\n",
    "}\n",
    "\n",
    "clf_logreg = tune_hyperparam(LogisticRegression, hyperparam_grid, X_train, y_train, fixed_hyperparams)\n",
    "compute_scores(clf_logreg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60006ae",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c840c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Training accuracy: 0.95\n",
      "Test accuarcy: 1.0\n",
      "Wall time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define hyperparameters to be searched during tuning\n",
    "hyperparam_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 9],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "clf_knn = tune_hyperparam(KNeighborsClassifier, hyperparam_grid, X_train, y_train)\n",
    "compute_scores(clf_knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7b5e4",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "991aa160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "Training accuracy: 1.0\n",
      "Test accuarcy: 0.9333333333333333\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define hyperparameters to be searched during tuning\n",
    "hyperparam_grid = {\n",
    "    'n_estimators': [50, 100, 500],\n",
    "    'max_features': ['sqrt', 'log2', 1/3]\n",
    "}\n",
    "\n",
    "# Define hyperparameters to be fixed\n",
    "fixed_hyperparams = {\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "clf_rf = tune_hyperparam(RandomForestClassifier, hyperparam_grid, X_train, y_train, fixed_hyperparams)\n",
    "compute_scores(clf_rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1c418",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9166db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'learning_rate': 0.5, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Training accuracy: 1.0\n",
      "Test accuarcy: 1.0\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define hyperparameters to be searched during tuning\n",
    "hyperparam_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.5, 0.1, 0.05, 0.01],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Define hyperparameters to be fixed\n",
    "fixed_hyperparams = {\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "clf_gbm = tune_hyperparam(GradientBoostingClassifier, hyperparam_grid, X_train, y_train, fixed_hyperparams)\n",
    "compute_scores(clf_gbm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663a3a0",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42d8c727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\thefo\\\\Documents\\\\git_repos\\\\app-iris-ml-react-fastapi\\\\models\\\\clf_gbm.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "joblib.dump(clf_logreg, MODELS_DIR / MODEL_LOGREG_FN)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "joblib.dump(clf_knn, MODELS_DIR / MODEL_KNN_FN)\n",
    "\n",
    "# Random Forest\n",
    "joblib.dump(clf_rf, MODELS_DIR / MODEL_RF_FN)\n",
    "\n",
    "# Gradient Boosting\n",
    "joblib.dump(clf_gbm, MODELS_DIR / MODEL_GBM_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443d3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
